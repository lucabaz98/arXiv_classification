{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieving\n",
    "In this part of the project, we have fetched the data from **ArXiv API** and created the dataset on which apply our Deep Learning strategies and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import arxiv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArXiv categories\n",
    "Each ArXiv article is associated with a **category group** and marked with a **category**, both of which could be our target value in the classification task.\n",
    "\n",
    "In the following section, we have collected all the **ArXiv categories** from the website using the **web scraping technique**.\n",
    "\n",
    "For each category we have this data:\n",
    "- *categoryId*: the ID of the category in the ArXiv taxonomy;\n",
    "- *categoryName*: the actual name of the category;\n",
    "- *categoryGroup*: the group of the category. We have choosen to aggregate the subgroups of the category \"Physics\" in a unique group, named **\"Physics\"**.\n",
    "\n",
    "Other information at this link: [ArXiv category taxonomy](https://arxiv.org/category_taxonomy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which detects the ArXiv category group starting from the categoryID of the article\n",
    "# Params: @category_group_id -> category ID of the article\n",
    "# Return: a string with the category group name\n",
    "def detectCategoryGroup(category_group_id):\n",
    "\n",
    "    if(category_group_id == 'cs'): return 'Computer Science'\n",
    "    if(category_group_id == 'econ'): return 'Economy'\n",
    "    if(category_group_id == 'eess'): return 'Electrical Engineering and Systems Science'\n",
    "    if(category_group_id == 'math'): return 'Mathematics'\n",
    "    if(category_group_id == 'q-bio'): return 'Quantitative Biology'\n",
    "    if(category_group_id == 'q-fin'): return 'Quantitative Finance'\n",
    "    if(category_group_id == 'stat'): return 'Statistics'\n",
    "    else: return 'Physics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_categories_url = \"https://arxiv.org/category_taxonomy\"\n",
    "arxiv_categories_html = requests.get(arxiv_categories_url)\n",
    "webpage_html = BeautifulSoup(arxiv_categories_html.content, \"html.parser\")\n",
    "arxiv_categories_html = webpage_html.findAll(\"div\", {\"class\": \"column is-one-fifth\"})\n",
    "\n",
    "arxiv_categories = []\n",
    "\n",
    "for category in arxiv_categories_html:\n",
    "\n",
    "    category_title = category.find(\"h4\")\n",
    "\n",
    "    if (category_title != None):\n",
    "\n",
    "        category_string = category_title.text.strip()\n",
    "        category_string_splitted = category_string.split(' ', 1)\n",
    "\n",
    "        arxiv_categories.append({ \n",
    "\n",
    "            'categoryId': category_string_splitted[0], \n",
    "            'categoryName': category_string_splitted[1].replace('(', '').replace(')',''),\n",
    "            'categoryGroup': detectCategoryGroup(category_string_splitted[0].split('.')[0])\n",
    "\n",
    "        })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArXiv API\n",
    "Here we have actually retrieved the data from the [ArXiv API](https://info.arxiv.org/help/api/index.html) using the related [library](http://lukasschwab.me/arxiv.py/index.html).\n",
    "\n",
    "We have also created a **Pandas dataframe** with the fetched data and written it in a **CSV file**, which will be read and processed later in the project.\n",
    "\n",
    "For each **ArXiv article** we have the following information available:\n",
    "- *link*: link to the article on the ArXiv platform;\n",
    "- *title*: title of the article;\n",
    "- *publishedDate*: date of the first publication;\n",
    "- *authors*: list of authors separated by a ',';\n",
    "- *abstract*: ArXiv abstract of the article;\n",
    "- *categoryId*: the ID of the category in the ArXiv taxonomy;\n",
    "- *categoryName*: the actual name of the category;\n",
    "- *categoryGroup*: the group of the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryNumber = 0\n",
    "\n",
    "for category in arxiv_categories:\n",
    "\n",
    "    categoryNumber = categoryNumber + 1\n",
    "    print(categoryNumber)\n",
    "\n",
    "    category_articles = arxiv.Search(\n",
    "\n",
    "        query = category['categoryId'],\n",
    "        max_results = 500,\n",
    "        sort_by = arxiv.SortCriterion.Relevance,\n",
    "        sort_order = arxiv.SortOrder.Descending\n",
    "\n",
    "    )\n",
    "\n",
    "    for category_article in category_articles.results():\n",
    "\n",
    "        authors = ''\n",
    "\n",
    "        for author in category_article.authors:\n",
    "            authors = authors + author.name + ', '\n",
    "\n",
    "        article_dict = {\n",
    "\n",
    "            'link': category_article.entry_id,\n",
    "            'title': category_article.title,\n",
    "            'publishedDate': category_article.published,\n",
    "            'authors': authors[:-2],\n",
    "            'abstract': category_article.summary,\n",
    "            'categoryId': category['categoryId'],\n",
    "            'categoryName': category['categoryName'],\n",
    "            'categoryGroup': category['categoryGroup']\n",
    "            \n",
    "        }\n",
    "\n",
    "        arxiv_dataset = arxiv_dataset.append(article_dict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_dataset.to_csv('arxiv-dataset.csv', encoding = 'utf-8', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
