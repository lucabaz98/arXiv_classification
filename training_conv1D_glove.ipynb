{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# from shutil import copyfile\n",
    "# copyfile('/content/drive/MyDrive/FDL Project/Code/text_vectorization.py', 'text_vectorization.py')\n",
    "# copyfile('/content/drive/MyDrive/FDL Project/Code/embedding.py', 'embedding.py')\n",
    "# copyfile('/content/drive/MyDrive/FDL Project/Code/kfold_cv.py', 'kfold_cv.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kfold_cv' from 'c:\\\\Users\\\\Luca\\\\Desktop\\\\arXiv_classification\\\\kfold_cv.py'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "#import nltk\n",
    "#nltk.data.path.append('C:\\\\Users\\\\della\\\\anaconda3\\\\nltk-data')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import pre_processing\n",
    "#importlib.reload(pre_processing)\n",
    "\n",
    "import text_vectorization\n",
    "#importlib.reload(text_vectorization)\n",
    "\n",
    "import embedding\n",
    "importlib.reload(embedding)\n",
    "\n",
    "import kfold_cv\n",
    "importlib.reload(kfold_cv)\n",
    "\n",
    "#import data_augmentation\n",
    "#importlib.reload(data_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set_processed = pre_processing.dataPreProcessing(train_set)\n",
    "#train_set_processed.to_csv('data/train-set-cat1-processed.csv', index = False)\n",
    "\n",
    "#train_set = pd.read_csv('/content/drive/MyDrive/FDL Project/Code/data/train-set-cat1-processed.csv')\n",
    "train_set = pd.read_csv('data/train-set-cat1-processed.csv')\n",
    "\n",
    "number_of_categories = len(train_set['label'].unique())\n",
    "# One-hot encoding of the labels\n",
    "label_train = to_categorical(train_set['label'], num_classes = number_of_categories, dtype = 'int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "words_per_sentence = 200\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer_keras = text_vectorization.createTextVectorizer(vocabulary_size, words_per_sentence, train_set['text'])\n",
    "vocabulary_keras = text_vectorizer_keras.get_vocabulary()\n",
    "\n",
    "embedding_matrix_glove = embedding.buildEmbeddingMatrix(embedding_dim, vocabulary_keras)\n",
    "embedding_layer_glove = embedding.createEmbeddingLayer(embedding_matrix_glove, None)\n",
    "embedding_layer_glove._name = 'GloVe'\n",
    "\n",
    "feature_train_glove = text_vectorization.textVectorization(train_set['text'], text_vectorizer_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = keras.Input(shape = (words_per_sentence,), dtype = 'int64')\n",
    "\n",
    "# Embedding layer\n",
    "x = embedding_layer_glove(input_layer)\n",
    "\n",
    "# Hidden layers\n",
    "x = keras.layers.Conv1D(filters = 128, kernel_size = 5, activation = 'relu')(x)\n",
    "x = keras.layers.GlobalMaxPooling1D()(x)\n",
    "x = keras.layers.Dropout(rate = 0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "x = keras.layers.Dense(number_of_categories, activation = 'softmax')(x)\n",
    "output_layer = x\n",
    "\n",
    "# Neural network model\n",
    "network = keras.Model(input_layer, output_layer, name = 'Conv1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = [{\n",
    "    'filters': 128,\n",
    "    'kernel_size': 5,\n",
    "    'rate': 0.5,\n",
    "    'optimizer': 'rmsprop',\n",
    "    'batch_size': 128\n",
    "    }\n",
    "    #  ,\n",
    "    #   {\n",
    "    #  'filters': 128,\n",
    "    #  'kernel_size': 5,\n",
    "    #  'rate': 0.5,\n",
    "    #  'optimizer': 'adam',\n",
    "    #  'batch_size': 128\n",
    "    #  }\n",
    "]\n",
    "epochs = 1\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 43s 194ms/step - loss: 1.2024 - accuracy: 0.6037\n",
      "212/212 [==============================] - 40s 190ms/step - loss: 0.9060 - accuracy: 0.7050\n",
      "[{'Network': 'Conv1D', 'Embedding': 'GloVe', 'filters': 128, 'kernel_size': 5, 'rate': 0.5, 'optimizer': 'rmsprop', 'batch_size': 128, 'loss_kfold': 0.797, 'accuracy_kfold': 0.736, 'best_number_epochs': 1}]\n"
     ]
    }
   ],
   "source": [
    "kfold_results = kfold_cv.kfoldCrossValidation(k, feature_train_glove, label_train, network, hyperparams, epochs)\n",
    "print(kfold_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
